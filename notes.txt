
GloVe from :: http://www-nlp.stanford.edu/projects/glove/

wget http://www-nlp.stanford.edu/software/glove.tar.gz
tar -xzf glove.tar.gz
cd glove
make 
# .. that's it ...

# run ./demo.sh for fun...
# 100Mb file, 17M words in sentences, 253k vocab 
# Actual training : 81k word vocab, vector-length : 50, max_iter 15
15:30 - 15:42 (finished earlier...)
23:48 - 23:55 (started earlier...)

wc data/orig/train_v2.txt 
  30,301,028  768,646,526 4,147,291,308 data/orig/train_v2.txt
wc data/orig/test_v2.txt
  306,682  7,481,193 43,045,391 data/orig/test_v2.txt

# The sample 'text8' corpus file appears to be just :
#   plain lowercase words
#   no punctuation
#   no line-gaps
#   numbers spelled out as digits
#   apostrophes->spaces

mkdir -p data/{orig,glove}

date
##  1MM 19s
#python src/make_corpus.py --input data/orig/train_v2.txt --output data/glove/corpus_1MM.txt --lines 1000000
##  10MM 3m25s
#python src/make_corpus.py --input data/orig/train_v2.txt --output data/glove/corpus_10MM.txt --lines 10000000
##   ALL 10m03s
#python src/make_corpus.py --input data/orig/train_v2.txt --output data/glove/corpus_ALL.txt
date


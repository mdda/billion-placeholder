
GloVe from :: http://www-nlp.stanford.edu/projects/glove/

wget http://www-nlp.stanford.edu/software/glove.tar.gz
tar -xzf glove.tar.gz
cd glove
make 
# .. that's it ...

# run ./demo.sh for fun...
# 100Mb file, 17M words in sentences, 253k vocab 
# Actual training : 81k word vocab, vector-length : 50, max_iter 15
15:30 - 15:42 (finished earlier...)
23:48 - 23:55 (started earlier...)

wc data/orig/train_v2.txt 
  30,301,028  768,646,526 4,147,291,308 data/orig/train_v2.txt
wc data/orig/test_v2.txt
  306,682  7,481,193 43,045,391 data/orig/test_v2.txt

# The sample 'text8' corpus file appears to be just :
#   plain lowercase words
#   no punctuation
#   no line-gaps
#   numbers spelled out as digits
#   apostrophes->spaces

mkdir -p data/{orig,glove,gaps,fill}

## Move the Kaggle training and test data into the right place
#rsync -avz --progress data/orig andrewsm@holland.herald:/home/andrewsm/sketchpad/kaggle/1-billion-words/data/

date
##  1MM 19s (laptop), 1MM 10s (holland)
#python src/make_corpus.py --input data/orig/train_v2.txt --output data/glove/1MM_0-corpus.txt --lines 1000000
##  10MM 3m25s
#python src/make_corpus.py --input data/orig/train_v2.txt --output data/glove/10MM_0-corpus.txt --lines 10000000
##   ALL 10m03s (laptop),  ALL 5m50s (holland)
#python src/make_corpus.py --input data/orig/train_v2.txt --output data/glove/ALL_0-corpus.txt
date

# 0.0722 -> 0.021555 in 12m (holland), 25m (laptop)
./src/corpus-glove.sh 1MM 
./src/corpus-glove.sh ALL 

python src/make_gaps_training.py --input data/glove/1MM_0-corpus.txt --vocab data/glove/1MM_1-vocab.txt --output data/gaps/1MM_train.txt 

